{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports para utilizar numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports para extraer datos de un archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports para dividir las fotos del dataset en entrenamiento y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports para limpiar la sesion e indicar rate de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports para convertir la foto a un array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports para que funcione y se imprima la matriz con los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports necesarios para que funcionen las peticiones POST al servidor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bottle import Bottle,route, run, request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports para que se pueda definir un modelo desde un json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports necesarios para que funcione la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports para archivos temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports para abrir la foto y poder manipularla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especificamos la ruta donde se encuentra el dataset a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'G:/datos/data/fer2013/fer2013.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas son las expresiones disponibles en el dataset\n",
    "- 0 : angry\n",
    "- 1 : disgust\n",
    "- 2 : fear\n",
    "- 3 : happy\n",
    "- 4 : sad\n",
    "- 5 : surprise\n",
    "- 6 : neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion para comprobar la estructura del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkData():\n",
    "    df=pd.read_csv(filename)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion para obtener los datos (X=pixels, Y=emotion) y almacenarlos en variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    # declaramos las variables contenedoras de los pixeles (X) y de las etiquetas (Y).\n",
    "    X = []\n",
    "    Y = []\n",
    "    # evitamos la primera linea que contiene los nombres de las columnas.\n",
    "    void = True\n",
    "    for line in open(filename):\n",
    "        if void:\n",
    "            void = False\n",
    "        else:\n",
    "            # dividimos la linea por la coma de forma que tenemos un array con los datos necesarios.\n",
    "            fila = line.split(',')\n",
    "            # apilamos los datos en las variables\n",
    "            Y.append(int(fila[0]))\n",
    "            X.append([int(p) for p in fila[1].split()])\n",
    "    # convertimos a numpy array para tratar los datos.\n",
    "    # ademas procesamos los pixeles de forma que todos tengan un valor entre 0 y 1 (dividimos entre 255).\n",
    "    X = np.array(X) / 255.0\n",
    "    Y = np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion para cargar los datos del dataset y llamar a la funcion train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    # llamamos a la funcion para obtener los datos del dataset\n",
    "    X,Y = getData()\n",
    "    # identificamos el numero de clases que existen(numero de expresiones faciales)\n",
    "    num_class = len(set(Y))\n",
    "    # redimensionamos X para que se adecue a la red neuronal (shape,size,size,gray)\n",
    "    N,D = X.shape\n",
    "    X = X.reshape(N, 48, 48, 1)\n",
    "    # creamos variables de entrenamiento\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)\n",
    "    Y_train = (np.arange(num_class) == Y_train[:, None]).astype(np.float32)\n",
    "    Y_test = (np.arange(num_class) == Y_test[:, None]).astype(np.float32)\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion que contiene el modelo CNN utilizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (5, 5), input_shape= (48,48,1) ,activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion que contiene otro modelo CNN que proporciona peores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model2():\n",
    "    INIT_LR = 1e-3\n",
    "    \n",
    "    model2 = Sequential()\n",
    "    model2.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(48,48,1)))\n",
    "    model2.add(LeakyReLU(alpha=0.1))\n",
    "    model2.add(MaxPooling2D((2, 2),padding='same'))\n",
    "    model2.add(Dropout(0.5))\n",
    "\n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dense(32, activation='linear'))\n",
    "    model2.add(LeakyReLU(alpha=0.1))\n",
    "    model2.add(Dropout(0.5)) \n",
    "    model2.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    model2.summary()\n",
    "\n",
    "    model2.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adagrad(lr=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])\n",
    "    \n",
    "    return model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion para mostrar la matriz con los resultados de los tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_matrix():\n",
    "    # cargamos los datos\n",
    "    X_train, X_test, Y_train, Y_test = loadData()   \n",
    "    count = 0\n",
    "    prep_predictions = model.predict_classes(X_test, batch_size=128, verbose=0)\n",
    "    prep_labels=np.argmax(Y_test, axis=1)\n",
    "    for i in range (len(prep_predictions)):\n",
    "        if prep_predictions[i]==prep_labels[i]:\n",
    "            count = count + 1\n",
    "    print('Porcentaje de acierto: ',count/len(prep_labels))\n",
    "    cm = confusion_matrix(prep_labels, prep_predictions)\n",
    "    %matplotlib inline\n",
    "    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "    y_pos = np.arange(len(objects))\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sn.heatmap(cm, annot=True)\n",
    "    plt.xlabel('PREDICCION')\n",
    "    plt.ylabel('REAL')\n",
    "    plt.xticks(y_pos,objects)\n",
    "    plt.yticks(y_pos,objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables principales a modificar dependiendo de los resultados que se quiera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable que indica si se quiere visualizar los datos\n",
    "check = False\n",
    "# variable que indica si existe un modelo guardado ya entrenado, si esta en False se entrena uno.\n",
    "model_saved = True\n",
    "# variable que indica si se debe imprimir la matriz para analizar resultados, debe de haber un modelo guardado y cargado.\n",
    "matrix = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Si se ha indicado, se muestran los datos tal y como estan en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if (check==True):\n",
    "    checkData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sabemos que existen 3 columnas:\n",
    "- emotion: indica que expresion tiene la persona de la foto.\n",
    "- pixels: la foto en pixeles.\n",
    "- usage: el uso que se le da a dicha foto (Training/PublicTest/PrivateTest).\n",
    "NOTA: usaremos posteriormente el 25% para test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se entrena un modelo CNN o se carga uno que ya existe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo ha sido cargado.\n"
     ]
    }
   ],
   "source": [
    "# comprobamos si existe un modelo guardado o no\n",
    "if(model_saved==False):\n",
    "    # solicitamos datos\n",
    "    X_train, X_test, Y_train, Y_test = loadData()\n",
    "    # limpiamos sesion para intentar evitar entrenamientos largos\n",
    "    K.tensorflow_backend.clear_session()\n",
    "    # definimos el modelo\n",
    "    model=my_model()\n",
    "    # usamos el bakend de keras y seleccionamos el rate de aprendizaje\n",
    "    K.set_value(model.optimizer.lr,1e-3)\n",
    "    # hacemos fit con un batch de tamaño 64 y 12 epoch\n",
    "    h=model.fit(x=X_train,     \n",
    "            y=Y_train, \n",
    "            batch_size=64, \n",
    "            epochs=10, \n",
    "            verbose=1, \n",
    "            validation_data=(X_test,Y_test),\n",
    "            shuffle=True\n",
    "            )\n",
    "    # pasamos el modelo a json para almacenarlo\n",
    "    model_json = model.to_json()\n",
    "    with open(\"expresionsjsonMODEL10.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # almacenamos en formato h5\n",
    "    model.save_weights(\"expressionsh5MODEL10.h5\")\n",
    "    print(\"El modelo ha sido generado y almacenado con exito.\")\n",
    "else:\n",
    "    # el modelo ya existe y no hace falta entrenar la NN, por lo que cargamos el json\n",
    "    json_file = open('expresionsjsonMODEL2.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # solo necesario si no tenemos un json a partir del que cargar nuestro modelo\n",
    "    #model=my_model() \n",
    "    # cargamos el archivo h5\n",
    "    model.load_weights(\"expressionsh5MODEL2.h5\")   \n",
    "    # compilamos el modelo para poder usarlo\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    print(\"El modelo ha sido cargado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Si se ha indicado, se muestra la matriz con los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (matrix==True):\n",
    "    # llamamos a la funcion que pinta el porcentaje de acierto y la matriz\n",
    "    my_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos apreciar la emocion 1 (disgust) no tiene buenos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion para realizar la predicion correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_prediction(ImArray):\n",
    "\n",
    "    porcentajes = model.predict(ImArray).tolist()\n",
    "    #retornamos los datos de la prediccion en formato json\n",
    "    return prepare_json(porcentajes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion que prepara los resultados para devolver un json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_json(porcentajes):\n",
    "    jsons = {\"expressions\":[]}\n",
    "    # recorremos los probabilidades de cada expresion\n",
    "    a=porcentajes[0]\n",
    "    for i in range(0,len(a)):\n",
    "        # establecemos como maximo 3 decimales\n",
    "        a[i] = round(a[i],3)\n",
    "        jsons[\"expressions\"].append({\"mood\":expressions[i],\"probability\":a[i]})\n",
    "    # devolvemos un json con todas las probabilidades\n",
    "    return jsons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion que prepara la foto recibida para que la CNN pueda interpretarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_photo(imagen):\n",
    "    # convertimos la foto a gris y a tamaño 48x48\n",
    "    img = imagen.convert('L').resize((48,48))\n",
    "    # devolvemos un array con los pixeles de la foto\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    x = x / 255\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peticion POST del lado del servidor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Bottle()\n",
    "@app.route(\"/getMood\", method=\"POST\")\n",
    "def do_upload():\n",
    "    \n",
    "    foto = request.files[\"photo\"]\n",
    "    # usamos un archivo temporal para poder manipular la foto\n",
    "    temporal = tempfile.TemporaryFile()\n",
    "    foto.save(temporal)\n",
    "    # es necesario que la foto tenga unas caracteristicas antes de ser mandada a la CNN, por ello primero se prepara\n",
    "    imagen_lista = prepare_photo(Image.open(temporal))\n",
    "    # realizamos la prediccion de la foto lista para poder ser interpretada por la CNN\n",
    "    resultado = do_prediction(imagen_lista)\n",
    "    # cerramos el archivo temporal\n",
    "    temporal.close()\n",
    "    \n",
    "    print(resultado)\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutamos el servidor para que se puedan realizar peticiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bottle v0.12.18 server starting up (using WSGIRefServer())...\n",
      "Listening on http://192.168.1.46:9004/\n",
      "Hit Ctrl-C to quit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run(app,host='192.168.1.46', port=9004, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
