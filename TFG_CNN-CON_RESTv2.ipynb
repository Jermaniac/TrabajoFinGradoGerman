{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from skimage import io\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "import json\n",
    "\n",
    "from bottle import Bottle,route, run, request\n",
    "import os\n",
    "\n",
    "# imports necesarios para que funcione la CNN\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESTO ES TEXTO - markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruta donde se encuentra nuestro dataset.\n",
    "filename = 'G:/datos/data/fer2013/fer2013.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkData():\n",
    "    # comprobamos la estructura que tiene nuestro dataset.\n",
    "    df=pd.read_csv(filename)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para obtener los datos (X=pixels, Y=emotion) y almacenarlos en variables.\n",
    "def getData():\n",
    "    # declaramos las variables contenedoras de los pixeles (X) y de las etiquetas (Y).\n",
    "    X = []\n",
    "    Y = []\n",
    "    # evitamos la primera linea que contiene los nombres de las columnas.\n",
    "    void = True\n",
    "    for line in open(filename):\n",
    "        if void:\n",
    "            void = False\n",
    "        else:\n",
    "            # dividimos la linea por la coma de forma que tenemos un array con los datos necesarios.\n",
    "            fila = line.split(',')\n",
    "            # apilamos los datos en las variables\n",
    "            Y.append(int(fila[0]))\n",
    "            X.append([int(p) for p in fila[1].split()])\n",
    "    # convertimos a numpy array para tratar los datos.\n",
    "    # ademas procesamos los pixeles de forma que todos tengan un valor entre 0 y 1 (dividimos entre 255).\n",
    "    X = np.array(X) / 255.0\n",
    "    Y = np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    # llamamos a la funcion para obtener los datos del dataset\n",
    "    X,Y = getData()\n",
    "    # identificamos el numero de clases que existen(numero de expresiones faciales)\n",
    "    num_class = len(set(Y))\n",
    "    # redimensionamos X para que se adecue a la red neuronal (shape,size,size,gray)\n",
    "    N,D = X.shape\n",
    "    X = X.reshape(N, 48, 48, 1)\n",
    "    # creamos variables de entrenamiento\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)\n",
    "    Y_train = (np.arange(num_class) == Y_train[:, None]).astype(np.float32)\n",
    "    Y_test = (np.arange(num_class) == Y_test[:, None]).astype(np.float32)\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (5, 5), input_shape= (48,48,1) ,activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model2():\n",
    "    INIT_LR = 1e-3\n",
    "    \n",
    "    model2 = Sequential()\n",
    "    model2.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(48,48,1)))\n",
    "    model2.add(LeakyReLU(alpha=0.1))\n",
    "    model2.add(MaxPooling2D((2, 2),padding='same'))\n",
    "    model2.add(Dropout(0.5))\n",
    "\n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dense(32, activation='linear'))\n",
    "    model2.add(LeakyReLU(alpha=0.1))\n",
    "    model2.add(Dropout(0.5)) \n",
    "    model2.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    model2.summary()\n",
    "\n",
    "    model2.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adagrad(lr=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])\n",
    "    \n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_matrix():\n",
    "    X_train, X_test, Y_train, Y_test = loadData()   \n",
    "    count = 0\n",
    "    prep_predictions = model.predict_classes(X_test, batch_size=128, verbose=0)\n",
    "    prep_labels=np.argmax(Y_test, axis=1)\n",
    "    for i in range (len(prep_predictions)):\n",
    "        if prep_predictions[i]==prep_labels[i]:\n",
    "            count = count + 1\n",
    "    print('Porcentaje de acierto: ',count/len(prep_labels))\n",
    "    cm = confusion_matrix(prep_labels, prep_predictions)\n",
    "    %matplotlib inline\n",
    "    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "    y_pos = np.arange(len(objects))\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sn.heatmap(cm, annot=True)\n",
    "    plt.xlabel('PREDICCION')\n",
    "    plt.ylabel('REAL')\n",
    "    plt.xticks(y_pos,objects)\n",
    "    plt.yticks(y_pos,objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estas son las expresiones disponibles en el dataset\n",
    "# 0 : angry\n",
    "# 1 : disgust\n",
    "# 2 : fear\n",
    "# 3 : happy\n",
    "# 4 : sad\n",
    "# 5 : surprise\n",
    "# 6 : neutral\n",
    "expressions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable que indica si se quiere visualizar los datos\n",
    "check = True\n",
    "# variable que indica si existe un modelo guardado ya entrenado\n",
    "model_saved = True\n",
    "# variable que indica si se debe imprimir la matriz para analizar resultados\n",
    "matrix = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       emotion                                             pixels        Usage\n",
      "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n",
      "1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n",
      "2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n",
      "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n",
      "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n",
      "...        ...                                                ...          ...\n",
      "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
      "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
      "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
      "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
      "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n",
      "\n",
      "[35887 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "if (check==True):\n",
    "    checkData()\n",
    "# ahora sabemos que existen 3 columnas:\n",
    "#    - emotion: indica que expresion tiene la persona de la foto.\n",
    "#    - pixels: la foto.\n",
    "#    - usage: el uso que se le da a dicha foto (Training/PublicTest/PrivateTest).\n",
    "# NOTA: usaremos todas las fotos del dataset pero posteriormente utilizaremos el 25% para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo ha sido cargado.\n"
     ]
    }
   ],
   "source": [
    "# comprobamos si existe un modelo guardado o no\n",
    "if(model_saved==False):\n",
    "    # solicitamos datos\n",
    "    X_train, X_test, Y_train, Y_test = loadData()\n",
    "    # limpiamos sesion para intentar evitar entrenamientos largos\n",
    "    K.tensorflow_backend.clear_session()\n",
    "    # entrenamos el modelo\n",
    "    model=my_model()\n",
    "    # usamos el bakend de keras y seleccionamos el rate de aprendizaje\n",
    "    K.set_value(model.optimizer.lr,1e-3)\n",
    "    # hacemos fit con un batch de tama√±o 64 y 12 epoch\n",
    "    h=model.fit(x=X_train,     \n",
    "            y=Y_train, \n",
    "            batch_size=64, \n",
    "            epochs=8, \n",
    "            verbose=1, \n",
    "            validation_data=(X_test,Y_test),\n",
    "            shuffle=True\n",
    "            )\n",
    "    # pasamos el modelo a json para almacenarlo\n",
    "    model_json = model.to_json()\n",
    "    with open(\"expresionsjsonMODEL7.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # almacenamos en formato h5\n",
    "    model.save_weights(\"expressionsh5MODEL7.h5\")\n",
    "    print(\"El modelo ha sido generado y almacenado con exito.\")\n",
    "else:\n",
    "    # el modelo ya existe y no hace falta entrenar la NN, por lo que cargamos el json\n",
    "    json_file = open('expresionsjsonMODEL2.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # solo necesario si no tenemos un json a partir del que cargar nuestro modelo\n",
    "    #model=my_model() \n",
    "    # cargamos el archivo h5\n",
    "    model.load_weights(\"expressionsh5MODEL2.h5\")   \n",
    "    # compilamos el modelo para poder usarlo\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    print(\"El modelo ha sido cargado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llamamos a la funcion que pinta el porcentaje de acierto y la matriz\n",
    "if (matrix==True):\n",
    "    my_matrix()\n",
    "# como podemos apreciar la emocion 1 (disgust) no tiene buenos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_prediction(name):\n",
    "    \n",
    "    # ESTO COLOCARLO FUERA DE ESTA FUNCION, LA CNN ES INDEPENDIENTE\n",
    "    img = image.load_img('G:/datos/TFG/photos/'+name)\n",
    "    img = img.convert('L').resize((48,48))\n",
    "    #show_img=image.load_img('G:/datos/TFG/photos/'+name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x = image.img_to_array(img)\n",
    "\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "\n",
    "    x = x / 255\n",
    "\n",
    "    porcentajes = model.predict(x).tolist()\n",
    "\n",
    "    # mostramos la foto que nos ha llegado\n",
    "    #plt.imshow(img)\n",
    "\n",
    "    jsons = {}\n",
    "    # recorremos los probabilidades de cada expresion, establecemos como maximo 3 decimales\n",
    "    a=porcentajes[0]\n",
    "    for i in range(0,len(a)):\n",
    "        a[i] = round(a[i],3)\n",
    "        jsons[expressions[i]]=a[i]\n",
    "    # devolvemos un json con todas las probabilidades\n",
    "    return jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bottle import static_file\n",
    "app = Bottle()\n",
    "@app.route(\"/getMood\", method=\"POST\")\n",
    "def do_upload():\n",
    "    upload = request.files.get(\"photo\")\n",
    "    save_path = \"/datos/TFG/photos/\"\n",
    "    file_path = \"{path}/{file}\".format(path=save_path, file=upload.filename)\n",
    "\n",
    "    \n",
    "    upload.save(file_path)\n",
    "    \n",
    "    resultado = do_prediction(upload.filename)\n",
    "    print(resultado)\n",
    "    print(type(resultado))\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bottle v0.12.18 server starting up (using WSGIRefServer())...\n",
      "Listening on http://192.168.1.46:9004/\n",
      "Hit Ctrl-C to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.0, 'disgust': 0.0, 'fear': 0.0, 'happy': 0.998, 'sad': 0.0, 'surprise': 0.0, 'neutral': 0.002}\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.39 - - [26/Mar/2020 13:38:01] \"POST /getMood HTTP/1.1\" 200 106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.0, 'disgust': 0.0, 'fear': 0.0, 'happy': 0.982, 'sad': 0.0, 'surprise': 0.0, 'neutral': 0.018}\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.39 - - [26/Mar/2020 13:38:09] \"POST /getMood HTTP/1.1\" 200 106\n",
      "G:\\Programs\\Anaconda3\\lib\\site-packages\\bottle.py:3139: ResourceWarning: unclosed <socket.socket fd=3892, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('192.168.1.46', 9004)>\n",
      "  pass\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "run(app,host='192.168.1.46', port=9004, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
